name: Scrape Ausport and update Sheet

on:
  schedule:
    - cron: '0 12 * * *'  # jalan tiap hari jam 12:00 UTC
  workflow_dispatch:       # bisa di-run manual

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    env:
      PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: "true"
      PUPPETEER_EXECUTABLE_PATH: "/usr/bin/chromium-browser"
      # Set di GitHub: Settings → Secrets and variables → Actions → New repository secret
      # Name: WEBAPP_URL  |  Value: https://script.google.com/macros/s/....../exec
      WEBAPP_URL: ${{ secrets.WEBAPP_URL }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Chromium
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser

      - name: Install dependencies
        run: npm install

      - name: Run scraper
        run: npm start

      - name: Commit CSV if exists & changed
        if: success()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          FILE="results.csv"

          # Kalau file nggak ada, jangan error
          if [ ! -f "$FILE" ]; then
            echo "CSV not found, skip commit"
            exit 0
          fi

          # Cek apakah file berubah (termasuk untracked)
          if git status --porcelain "$FILE" | grep . > /dev/null; then
            echo "Changes found, committing CSV"
            git add "$FILE"
            git commit -m "Update $FILE" || echo "Nothing to commit"
            git push
          else
            echo "No changes in CSV, skip commit"
          fi
