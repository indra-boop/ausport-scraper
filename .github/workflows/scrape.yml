name: Scrape Ausport and update Sheet

on:
  schedule:
    - cron: '0 12 * * *'  # jalan tiap hari jam 12:00 UTC
  workflow_dispatch:       # bisa di-run manual

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    env:
      PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: "true"
      PUPPETEER_EXECUTABLE_PATH: "/usr/bin/chromium-browser"

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Chromium
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser

      - name: Install dependencies
        run: npm install

      - name: Run scraper
        run: npm start

      - name: Commit CSV if exists & changed
        if: success()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Kalau file nggak ada (scraper gagal / timeout), jangan error
          if [ ! -f live_sports.csv ]; then
            echo "CSV not found, skip commit"
            exit 0
          fi

          # Kalau tidak ada perubahan di file, jangan commit
          if git diff --quiet --exit-code live_sports.csv; then
            echo "No changes in CSV, skip commit"
            exit 0
          fi

          echo "Changes found, committing CSV"
          git add live_sports.csv
          git commit -m "Update live_sports.csv"
          git push
