name: Scrape Ausport and update Sheet

on:
  schedule:
    - cron: "0 12 * * *"  # jalan tiap hari jam 12:00 UTC
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: scrape-ausport
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest

    env:
      PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: "true"
      # executable path akan kita set setelah install chromium
      WEBAPP_URL: ${{ secrets.WEBAPP_URL }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install Chromium
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium
          echo "PUPPETEER_EXECUTABLE_PATH=$(which chromium)" >> $GITHUB_ENV

      - name: Install dependencies
        run: npm ci

      - name: Run scraper
        run: node scraper.js

      - name: Commit CSV if exists & changed
        if: success()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          FILE="results.csv"

          if [ ! -f "$FILE" ]; then
            echo "CSV not found, skip commit"
            exit 0
          fi

          if git status --porcelain "$FILE" | grep . > /dev/null; then
            echo "Changes found, committing CSV"
            git add "$FILE"
            git commit -m "Update $FILE" || echo "Nothing to commit"
            git push
          else
            echo "No changes in CSV, skip commit"
          fi
